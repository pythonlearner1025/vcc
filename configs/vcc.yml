run_name: scrna_to_vcc_diffusion
#resume_from: checkpoints/scrna_to_vcc_diffusion_20250820_072032/checkpoint_ep121.pt
output_dir: checkpoints
seed: 42
device: cuda
amp_dtype: bf16
use_wandb: true
wandb_project: vcc-st-diffusion
eval_mode: false
test_prep_mode: false
test_genes_path: data/vcc_data/pert_counts_Validation.csv

model:
  model_class: models.diffusion:ConditionalDiffusionTransformer
  config_class: models.diffusion:ConditionalModelConfig
  config_args:
    dim: 640
    n_head: 16
    n_group: 16
    n_layer: 12
    ffn_mult: 8
    # Learned set compressor: SÂ·M = S * n_latents 
    n_latents: 256
    compressor_iters: 1
    use_memory_rope: true  # Apply RoPE to memory tokens for structured attention
    vocab_size: 31
    token_max_value: 10.82
    n_genes: 6288
    n_total_genes: 6288
    gene_embed_dim: 640
    n_technical_batches: 48
    batch_embed_dim: 40
    use_batch_conditioning: false
    n_timesteps: 64
    schedule: cosine
    pretrain_mask_ratio: 0.65
    finetune_mask_ratio_end: 1.0
    finetune_mask_ratio_steps: 10000
    finetune_full_mask_prob: 0.05
    use_fp8: false
    full_eval: true
    use_aux: false
    esm_matrix_path: esm_all.pt

optimizer:
  optimizer_class: models.diffusion:create_muon_optimizer
  optimizer_args: {}

loss:
  loss_class: engine.losses:DiffusionLoss
  loss_args:
    diffusion_class: models.diffusion:AbsorbingMaskMD4Continuous
    # Aux loss knobs
    lambda_de: 0.05 #0.05
    lambda_dir: 0.02 #0.02
    lambda_rank: 0.02 #0.020
    de_pos_weight: 9.0
    signif_mode: percentile
    signif_arg: 0.1

# Datasets stack with wrappers that compute HVGs/tokenizers internally
# Provide simple arguments only.
datasets:
  - name: scrna_pretrain
    dataloader_factory: wrappers.factories:create_scrna_pretrain
    dataloader_args:
      data_dir: data/scRNA/processed
      hvg_info_path: assets/hvg_seuratv3_6288.txt
      batch_size: 128
      vocab_size: 31
      max_value: 10.82
      num_workers: 4
    epochs: 1
    log_every_steps: 1
    save_every_steps: 1500
    eval_every_epochs: 1
    max_steps: null
    muon_lr: 0.03
    adam_lr: 0.0003
    warmup_steps: 1000
    token_weighting_annealing_steps: 1

  - name: vcc_finetune
    dataloader_factory: wrappers.factories:create_vcc_finetune
    dataloader_args:
      adata_path: /competition_train.h5
      hvg_info_path: assets/hvg_seuratv3_6288.txt
      set_size: 32
      vocab_size: 31
      max_value: 10.82 
      batch_size: 128
      n_samples_per_gene_train: 10
      n_samples_per_gene_val: 1
      train_split: 0.8
      num_workers: 4
      random_seed: 42
      blacklist_path: assets/blacklist.txt
    epochs: 100 
    log_every_steps: 1
    save_every_steps: 15000
    eval_every_epochs: 30
    max_steps: null
    muon_lr: 0.02
    adam_lr: 0.0002
    warmup_steps: 30
    token_weighting_annealing_steps: 1