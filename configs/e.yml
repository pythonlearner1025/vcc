run_name: scrna_to_vcc_diffusion
#resume_from: checkpoints/scrna_to_vcc_diffusion_20250811_234339/checkpoint_ep9.pt
output_dir: checkpoints
seed: 42
device: cuda
amp_dtype: bf16
use_wandb: true
wandb_project: vcc-st-diffusion
eval_mode: false
test_prep_mode: false
test_genes_path: data/vcc_data/pert_counts_Validation.csv

model:
  model_class: models.diffusion:ConditionalDiffusionTransformer
  config_class: models.diffusion:ConditionalModelConfig
  config_args:
    #n_xattn_loops: 12
    dim: 784
    n_head: 16
    n_layer: 16
    ffn_mult: 8
    # Learned set compressor: SÂ·M = S * n_latents 
    n_latents: 256
    compressor_iters: 2
    use_memory_rope: true  # Apply RoPE to memory tokens for structured attention
    vocab_size: 128
    token_max_value: 10.82
    n_genes: 6288
    n_total_genes: 6288
    gene_embed_dim: 784
    n_technical_batches: 48
    batch_embed_dim: 40
    use_batch_conditioning: false
    n_timesteps: 16
    schedule: cosine
    pretrain_mask_ratio: 0.65
    finetune_mask_ratio_end: 1.0
    finetune_mask_ratio_steps: 10000
    finetune_full_mask_prob: 0.05
    use_fp8: false
    full_eval: true
    use_aux: false

optimizer:
  optimizer_class: models.diffusion:create_muon_optimizer
  optimizer_args: {}

loss:
  loss_class: engine.losses:DiffusionLoss
  loss_args:
    diffusion_class: models.diffusion:AbsorbingMaskMD4Continuous
    # Aux loss knobs
    lambda_de: 0.05
    lambda_dir: 0.02
    lambda_rank: 0.020
    de_pos_weight: 9.0
    signif_mode: percentile
    signif_arg: 0.1

# Datasets stack with wrappers that compute HVGs/tokenizers internally
# Provide simple arguments only.
datasets:
  # - name: orion_finetune
  #   dataloader_factory: wrappers.factories:create_orion_finetune
  #   dataloader_args:
  #     data_dir: data/batched_5e4_norm
  #     hvg_info_path: assets/hvg_seuratv3_6288.txt
  #     set_size: 32
  #     batch_size: 4
  #     vocab_size: 128
  #     max_value: 10.82
  #     num_workers: 4
  #   epochs: 1
  #   log_every_steps: 1
  #   save_every_steps: 1500
  #   eval_every_epochs: 3
  #   max_steps: 1000000
  #   muon_lr: 0.02
  #   adam_lr: 0.0002
  #   warmup_steps: 125
  #   token_weighting_annealing_steps: 1

  - name: vcc_finetune
    dataloader_factory: wrappers.factories:create_vcc_finetune
    dataloader_args:
      adata_path: /competition_train.h5
      hvg_info_path: assets/hvg_seuratv3_6288.txt
      set_size: 32
      vocab_size: 128
      max_value: 10.82 
      batch_size: 5
      n_samples_per_gene_train: 10
      n_samples_per_gene_val: 1
      train_split: 0.8
      num_workers: 4
      random_seed: 42
      blacklist_path: assets/blacklist.txt
    epochs: 9
    log_every_steps: 1
    save_every_steps: 1500
    eval_every_epochs: 3
    max_steps: null
    muon_lr: 0.02
    adam_lr: 0.0001
    warmup_steps: 250
    token_weighting_annealing_steps: 1